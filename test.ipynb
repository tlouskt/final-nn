{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb6320bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import nn, io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "205d327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from numpy.typing import ArrayLike\n",
    "\n",
    "def sample_seqs(seqs: List[str], labels: List[bool]) -> Tuple[List[str], List[bool]]:\n",
    "    \"\"\"\n",
    "    This function should sample the given sequences to account for class imbalance. \n",
    "    Consider this a sampling scheme with replacement.\n",
    "    \n",
    "    Args:\n",
    "        seqs: List[str]\n",
    "            List of all sequences.\n",
    "        labels: List[bool]\n",
    "            List of positive/negative labels\n",
    "\n",
    "    Returns:\n",
    "        sampled_seqs: List[str]\n",
    "            List of sampled sequences which reflect a balanced class size\n",
    "        sampled_labels: List[bool]\n",
    "            List of labels for the sampled sequences\n",
    "    \"\"\"\n",
    "    #initialize output\n",
    "    sampled_seqs = []\n",
    "    sampled_labels = []\n",
    "\n",
    "    #get positive and negative sequences\n",
    "    pos_seqs = seqs[labels == True]\n",
    "    neg_seqs = seqs[labels == False]\n",
    "\n",
    "    #if balanced\n",
    "    if len(pos_seqs) == len(neg_seqs):\n",
    "        sampled_seqs = list(seqs)\n",
    "        sampled_labels = list(labels)\n",
    "    #if pos < neg, sample positive more with replacement with length of negative seqs\n",
    "    elif len(pos_seqs) < len(neg_seqs):\n",
    "        over_pos = pos_seqs[np.random.choice(len(pos_seqs), len(neg_seqs), replace = True)]\n",
    "        #new list of sequences and labels that correspond to oversampled dataset\n",
    "        sampled_seqs = list(np.concatenate(neg_seqs, over_pos), axis=None)\n",
    "        sampled_labels = list([True] * len(over_pos) + [False] * len(neg_seqs))\n",
    "    #if neg < pos, sample negative more\n",
    "    else:\n",
    "        len(pos_seqs) > len(neg_seqs)\n",
    "        over_neg = neg_seqs[np.random.choice(len(neg_seqs), len(pos_seqs), replace = True)]\n",
    "        sampled_seqs = list(np.concatenate(pos_seqs, over_neg), axis=None)\n",
    "        sampled_labels = list([True] * len(pos_seqs) + [False] * len(over_neg))\n",
    "\n",
    "    return sampled_seqs, sampled_labels\n",
    "\n",
    "\n",
    "def one_hot_encode_seqs(seq_arr: List[str]) -> ArrayLike:\n",
    "    \"\"\"\n",
    "    This function generates a flattened one-hot encoding of a list of DNA sequences\n",
    "    for use as input into a neural network.\n",
    "\n",
    "    Args:\n",
    "        seq_arr: List[str]\n",
    "            List of sequences to encode.\n",
    "\n",
    "    Returns:\n",
    "        encodings: ArrayLike\n",
    "            Array of encoded sequences, with each encoding 4x as long as the input sequence.\n",
    "            For example, if we encode:\n",
    "                A -> [1, 0, 0, 0]\n",
    "                T -> [0, 1, 0, 0]\n",
    "                C -> [0, 0, 1, 0]\n",
    "                G -> [0, 0, 0, 1]\n",
    "            Then, AGA -> [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0].\n",
    "    \"\"\"\n",
    "    encoding = {\n",
    "        \"A\": [1, 0, 0, 0],\n",
    "        \"T\": [0, 1, 0, 0],\n",
    "        \"C\": [0, 0, 1, 0],\n",
    "        \"G\": [0, 0, 0, 1]\n",
    "    }\n",
    "    #initialize list to store one hot encoded sequence where dims are num sequences in arr and then length of seq*4 for one-hot\n",
    "    one_hot_encodings = []\n",
    "    #iterate through each sequence\n",
    "    for seq in seq_arr:\n",
    "        #list to store one hot bases in current sequenc\n",
    "        base_one_hot = []\n",
    "        #iterate through each base in sequence\n",
    "        for base in seq:\n",
    "            #add the one hot encoded base to list\n",
    "            base_one_hot.append(encoding[base])\n",
    "        #add flattened seq encoding to list of encodings\n",
    "        base_one_hot = np.array(base_one_hot)\n",
    "        base_one_hot = base_one_hot.flatten()\n",
    "        one_hot_encodings.append(base_one_hot)\n",
    "    return np.array(one_hot_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55f980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "3163\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "pos = io.read_text_file(\"./data/rap1-lieb-positives.txt\")\n",
    "neg = io.read_fasta_file(\"./data/yeast-upstream-1k-negative.fa\")\n",
    "print(len(pos))\n",
    "print(len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062b53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_neg = []\n",
    "target_length = len(pos[50])\n",
    "\n",
    "for seq in neg:\n",
    "    for i in range (0, len(seq), target_length):\n",
    "        sub_neg_seq = seq[i:i+target_length]\n",
    "        short_neg.append(sub_neg_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7e30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seq = pos + short_neg\n",
    "labels = [True] * len(pos) + [False] * len(short_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7b39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_seqs, sampled_labels = sample_seqs(all_seq, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1330c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (149276,)\n",
      "Validation shape: (37320,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/wmhs7bhj31q6msm9t8w9qd780000gq/T/ipykernel_99278/3810625128.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(one_hot_encodings)\n"
     ]
    }
   ],
   "source": [
    "X =one_hot_encode_seqs(sampled_seqs)\n",
    "y = np.array(sampled_labels, dtype=object)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print(f\"Training shape: {X_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
